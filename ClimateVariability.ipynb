{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5NtuC5e+qJgrO/4dFw16w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidnoone/GEOPHYS_NOTEBOOKS/blob/main/ClimateVariability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Climate variability"
      ],
      "metadata": {
        "id": "brqRz1GoT9y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the data files\n",
        "!test ! -f meiv2.data && wget -O meiv2.data http://kete.rangi.cloud.edu.au/u/dcn/meiv2.data\n",
        "!test ! -f ERA5_monthly_surface.nc && wget -O ERA5_monthly_surface.nc http://kete.rangi.cloud.edu.au/u/dcn/ERA5_monthly_surface.nc\n",
        "!test ! -f ERA5_monthly_4layer.nc && wget -O ERA5_monthly_4layer.nc http://kete.rangi.cloud.edu.au/u/dcn/ERA5_monthly_4layer.nc"
      ],
      "metadata": {
        "id": "5mU8ezixUZ0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3ATRaKAT9Mq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy import linalg\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "  import netCDF4 as nc\n",
        "except:\n",
        "  !pip install netCDF4\n",
        "  import netCDF4 as nc\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ncdump\n",
        "ncdump is a little (unix) tool for showing the contents of a netcdf file.\n",
        "Here is a python function which is similar. "
      ],
      "metadata": {
        "id": "-8p5cbyxUtnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: show contents of netcdf file (like \"ncdump\" on )\n",
        "def ncdump(nc_fid, verb=True):\n",
        "    '''\n",
        "    ncdump outputs dimensions, variables and their attribute information.\n",
        "    The information is similar to that of NCAR's ncdump utility.\n",
        "    ncdump requires a valid instance of Dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    nc_fid : netCDF4.Dataset\n",
        "        A netCDF4 dateset object\n",
        "    verb : Boolean\n",
        "        whether or not nc_attrs, nc_dims, and nc_vars are printed\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    nc_attrs : list\n",
        "        A Python list of the NetCDF file global attributes\n",
        "    nc_dims : list\n",
        "        A Python list of the NetCDF file dimensions\n",
        "    nc_vars : list\n",
        "        A Python list of the NetCDF file variables\n",
        "    '''\n",
        "    def print_ncattr(key):\n",
        "        \"\"\"\n",
        "        Prints the NetCDF file attributes for a given key\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        key : unicode\n",
        "            a valid netCDF4.Dataset.variables key\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"\\t\\ttype:\", repr(nc_fid.variables[key].dtype))\n",
        "            for ncattr in nc_fid.variables[key].ncattrs():\n",
        "                print('\\t\\t%s:' % ncattr,\\\n",
        "                      repr(nc_fid.variables[key].getncattr(ncattr)))\n",
        "        except KeyError:\n",
        "            print(\"\\t\\tWARNING: %s does not contain variable attributes\" % key)\n",
        "\n",
        "    # NetCDF global attributes\n",
        "    nc_attrs = nc_fid.ncattrs()\n",
        "    if verb:\n",
        "        print(\"NetCDF Global Attributes:\")\n",
        "        for nc_attr in nc_attrs:\n",
        "            print('\\t%s:' % nc_attr, repr(nc_fid.getncattr(nc_attr)))\n",
        "    nc_dims = [dim for dim in nc_fid.dimensions]  # list of nc dimensions\n",
        "    # Dimension shape information.\n",
        "    if verb:\n",
        "        print(\"NetCDF dimension information:\")\n",
        "        for dim in nc_dims:\n",
        "            print(\"\\tName:\", dim )\n",
        "            print(\"\\t\\tsize:\", len(nc_fid.dimensions[dim]))\n",
        "            print_ncattr(dim)\n",
        "    # Variable information.\n",
        "    nc_vars = [var for var in nc_fid.variables]  # list of nc variables\n",
        "    if verb:\n",
        "        print(\"NetCDF variable information:\")\n",
        "        for var in nc_vars:\n",
        "            if var not in nc_dims:\n",
        "                print('\\tName:', var)\n",
        "                print(\"\\t\\tdimensions:\", nc_fid.variables[var].dimensions)\n",
        "                print(\"\\t\\tsize:\", nc_fid.variables[var].size)\n",
        "                print_ncattr(var)\n",
        "    return nc_attrs, nc_dims, nc_vars"
      ],
      "metadata": {
        "id": "BpVN_sBSveCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Open and read the data"
      ],
      "metadata": {
        "id": "yUjvBznj1IA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open and read the netcdf files\n",
        "file_erap = 'ERA5_monthly_4layer.nc'\n",
        "\n",
        "file_eras = 'ERA5_monthly_surface.nc'\n",
        "\n",
        "f_id = nc.Dataset(file_eras,'r')\n",
        "ncdump(f_id,verb=True)\n"
      ],
      "metadata": {
        "id": "B1x65qAJUs_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open and read the MEI data file\n",
        "file_mei = 'meiv2.data'\n",
        "columns = ['Year', 'Jan', 'Feb', 'Mar', 'Apr', 'May', \n",
        "                   'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "df = pd.read_csv(file_mei, sep='\\s+', header=None, names=columns)\n"
      ],
      "metadata": {
        "id": "EosyGkNXUGDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example function to perform PCA"
      ],
      "metadata": {
        "id": "iiBAIMy0UzRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pca(X):\n",
        "  \"\"\" A simple principle component analysis \"\"\"\n",
        "  \n",
        "  # Compute the mean, and center the data \n",
        "  mean = np.mean(X, axis=0)\n",
        "  X_centered = X - mean\n",
        "\n",
        "  # Compute the covariance matrix\n",
        "  covariance_matrix = np.cov(X_centered, rowvar=False)\n",
        "\n",
        "  # Calulate the eigen values/vectors of the covariance\n",
        "  eigenvalues, eigenvectors = linalg.eigh(covariance_matrix)\n",
        "\n",
        "  # Sort these, since python (actually LAPACK!) doesn't do it\n",
        "  idx = np.argsort(eigenvalues)[::-1]\n",
        "  eigenvalues = eigenvalues[idx]\n",
        "  eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "  ## Select just the top \"numcomponents\"\n",
        "  #X_transformed = np.dot(X_centered, eigenvectors[:, :num_components])\n",
        "\n",
        "  return eigenvalues, eigenvectors"
      ],
      "metadata": {
        "id": "G0PzU85NUywq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ntime = 50\n",
        "nlon = 144\n",
        "nlat = 72\n",
        "fake_data = np.random.random((ntime,nlon,nlat))\n",
        "\n",
        "#eval, evec = pca(fake_data.reshape(ntime,nlon*nlat))\n",
        "eval, evec = pca(np.transpose(fake_data.reshape(ntime,nlon*nlat)))\n",
        "\n"
      ],
      "metadata": {
        "id": "H34Jlm53T9lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 1: regression maps"
      ],
      "metadata": {
        "id": "JdxeQKunXNbK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZYF6wDlXNAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2: patterns of variability"
      ],
      "metadata": {
        "id": "nU5FvFBfXQE1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XkJK7fqTXPRL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}